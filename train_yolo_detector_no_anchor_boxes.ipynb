{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_yolo_detector_no_anchor_boxes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "M_cuaubdkwEg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><h1>That notebook is suited to run everything under google colab gpu runtime and sync files with google drive using pydrive</h1></center>"
      ]
    },
    {
      "metadata": {
        "id": "CaPd6bSK_vq5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#In google colab /tmp is not mounted under tmpfs that results in slow shared memory speed\n",
        "#Mount it only if running on google colab\n",
        "!mount -t tmpfs tmpfs -o size=12G /tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9536745ecfed905af28cda95c4cd6f7bf8e2ac48",
        "id": "X5yX-1XYecj1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1c953e067917efbb0eaed7a7b076a4e1f9129ab",
        "id": "nEGfdcNOecj5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Init_PyDrive():\n",
        "  global ID_BY_NAME\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "\n",
        "  auth.authenticate_user()\n",
        "  global gauth\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  global drive\n",
        "  drive = GoogleDrive(gauth)\n",
        "  ID_BY_NAME = dict()\n",
        "  file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "  for i in file_list:\n",
        "    print(i['title'])\n",
        "    ID_BY_NAME[i['title']] = i['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SE6l9LTF_Y0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Init_PyDrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "865443eb9d941ec2308f60743a876dc3f9e2efb7",
        "id": "3BAZ_Qg4ecj7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Download_File(filename, savename):\n",
        "  file = drive.CreateFile({'id': ID_BY_NAME[filename]})\n",
        "  file.GetContentFile(savename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db3754f84ee9f69b547717ef4cefa1b5c57c0660",
        "id": "stMj6x_Wecj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Upload_File(filename, drivename):\n",
        "  file = drive.CreateFile({\"title\": drivename})\n",
        "  file.SetContentFile(filename)\n",
        "  file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IW06acmx_l3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Download_File(\"WIDER_train.zip\", \"WIDER_train.zip\")\n",
        "Download_File(\"WIDER_val.zip\", \"WIDER_val.zip\")\n",
        "Download_File(\"wider_face_split.zip\", \"wider_face_split.zip\")\n",
        "Download_File(\"size_index_wider.txt\", \"size_index_wider.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GNFYA27U7xH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip -q WIDER_train.zip\n",
        "!unzip -q WIDER_val.zip\n",
        "!unzip -q wider_face_split.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SDfvJ55Z8Nyn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -f *.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GO2IjIFqrNix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -alh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMJeT0CjZgee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Download_File(\"fdmobilenet.py\", \"fdmobilenet.py\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "_kg_hide-input": false,
        "_kg_hide-output": false,
        "id": "3_lnaY0ceckC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import tensorflow as tf\n",
        "import math\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Input, ZeroPadding2D, Reshape, UpSampling2D, Concatenate, Lambda, Layer, DepthwiseConv2D, Multiply, GlobalAveragePooling2D, Activation, Dropout, Add\n",
        "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from tensorflow.python.keras.models import Model, load_model\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from multiprocessing import Process\n",
        "from google.colab import files\n",
        "from keras.utils import plot_model\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from imgaug import augmenters as ia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_bs5OqRTa7gk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from fdmobilenet import FDMobileNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OLjnGNCgqQVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "SEED = int(time.time())\n",
        "TRAIN_NUM_PARTS = 28\n",
        "VAL_NUM_PARTS = 7\n",
        "AVG_BYTES = 4 * 1000 * 1000\n",
        "BOX_THRESHOLD = 0.5\n",
        "NOFACES_RATE = 0.25\n",
        "NOFACES_MIN_SIZE = IMAGE_SIZE\n",
        "DEBUG = False\n",
        "\n",
        "MIN_FACE_SIZE = 0.05\n",
        "MIN_CROP_SIZE = IMAGE_SIZE\n",
        "GRIDS = [IMAGE_SIZE // 32]\n",
        "\n",
        "TRAIN_BBX_PATH = \"./wider_face_split/wider_face_train_bbx_gt.txt\"\n",
        "TRAIN_IMAGES_PREFIX = \"./WIDER_train/images/\"\n",
        "VAL_BBX_PATH = \"./wider_face_split/wider_face_val_bbx_gt.txt\"\n",
        "VAL_IMAGES_PREFIX = \"./WIDER_val/images/\"\n",
        "SIZE_INDEX = \"./size_index_wider.txt\"\n",
        "\n",
        "HS_RANGE = 15\n",
        "G_PROB = 0.5\n",
        "G_MAX = 0.6\n",
        "FLIP_PROB = 0.5\n",
        "NOISE_LEVEL = 0.05\n",
        "NOISE_PROB = 0.25\n",
        "NOISE_CHANNEL_PROB = 0.5\n",
        "CONTRAST_NORM_MIN = 0.75\n",
        "CONTRAST_NORM_MAX = 1.5\n",
        "\n",
        "def ATTRIBUTE_MASK(blur, expression, illumination, invalid, occlusion, pose):\n",
        "  return occlusion != 2 and blur != 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EmW9oACWFUbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from multiprocessing import RawValue, RawArray\n",
        "from numpy.ctypeslib import ctypes as ct\n",
        "import numpy as np\n",
        "\n",
        "class SharedImageArray:\n",
        "  def __init__(self, maxmemory, maxlen):\n",
        "    self.maxmemory = RawValue(ct.c_size_t, maxmemory)\n",
        "    self.maxlen = RawValue(ct.c_size_t, maxlen)\n",
        "    \n",
        "    self.i = RawValue(ct.c_size_t, 0)\n",
        "    self.i_offset = RawValue(ct.c_size_t, 0)\n",
        "    \n",
        "    self.shape_0 = RawArray(ct.c_size_t, maxlen)\n",
        "    self.shape_1 = RawArray(ct.c_size_t, maxlen)\n",
        "    self.offset = RawArray(ct.c_size_t, maxlen)\n",
        "    self.size = RawArray(ct.c_size_t, maxlen)\n",
        "    \n",
        "    self.array = RawArray(ct.c_uint8, maxmemory)\n",
        "  \n",
        "  def push(self, arr):\n",
        "    if self.i.value >= self.maxlen.value:\n",
        "      raise ValueError('i >= maxlen')\n",
        "    \n",
        "    assert len(arr.shape) == 3\n",
        "    assert arr.shape[2] == 3\n",
        "    assert arr.dtype == np.uint8\n",
        "    \n",
        "    arr_size = arr.shape[0] * arr.shape[1] * 3\n",
        "    \n",
        "    if self.i_offset.value + arr_size >= self.maxmemory.value:\n",
        "      raise ValueError('offset >= maxmemory')\n",
        "    \n",
        "    memoryview(self.array).cast('B')[self.i_offset.value:(self.i_offset.value + arr_size)] = arr.flatten()\n",
        "    \n",
        "    self.size[self.i.value] = arr_size\n",
        "    self.offset[self.i.value] = self.i_offset.value\n",
        "    self.shape_1[self.i.value] = arr.shape[1]\n",
        "    self.shape_0[self.i.value] = arr.shape[0]\n",
        "\n",
        "    self.i_offset.value += arr_size\n",
        "    self.i.value += 1\n",
        "\n",
        "  def len(self):\n",
        "    return self.i.value\n",
        "  \n",
        "  def get(self, index):\n",
        "    return np.frombuffer(memoryview(self.array).cast('B'), np.uint8, self.size[index], self.offset[index]).reshape(self.shape_0[index], self.shape_1[index], 3)\n",
        "  \n",
        "  def clear(self):\n",
        "    self.i.value = 0\n",
        "    self.i_offset.value = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CgWPvlB_BGRe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataPipeline(object):\n",
        "  def __random_quad(self, x1, y1, x2, y2, W, H):\n",
        "    if x1 > W or x2 > W or y1 > H or y2 > H:\n",
        "      return (None, None), (None, None)\n",
        "   \n",
        "    VERTICAL = 0\n",
        "    HORIZONTAL = 1\n",
        "\n",
        "    def intersect(p, k, l, r, t):\n",
        "        if t == VERTICAL:\n",
        "            x_i = p\n",
        "            y_i = p - k\n",
        "            if y_i >= l and y_i <= r:\n",
        "                return (x_i, y_i)\n",
        "            return None\n",
        "        else:\n",
        "            y_i = p\n",
        "            x_i = p + k\n",
        "            if x_i >= l and x_i <= r:\n",
        "                return (x_i, y_i)\n",
        "            return None\n",
        "\n",
        "    def cuts(k):\n",
        "        m1 = []\n",
        "        m2 = []\n",
        "\n",
        "        a1 = intersect(0, k, 0, y1, VERTICAL)\n",
        "        a2 = intersect(x1, k, 0, y1, VERTICAL)\n",
        "        a3 = intersect(0, k, 0, x1, HORIZONTAL)\n",
        "        a4 = intersect(y1, k, 0, x1, HORIZONTAL)\n",
        "        a5 = intersect(x2, k, y2, H, VERTICAL)\n",
        "        a6 = intersect(W, k, y2, H, VERTICAL)\n",
        "        a7 = intersect(y2, k, x2, W, HORIZONTAL)\n",
        "        a8 = intersect(H, k, x2, W, HORIZONTAL)\n",
        "\n",
        "        for i in [a1, a2, a3, a4]:\n",
        "            if not(i is None):\n",
        "                m1.append(i)\n",
        "\n",
        "        for i in [a5, a6, a7, a8]:\n",
        "            if not(i is None):\n",
        "                m2.append(i)\n",
        "\n",
        "        return m1, m2\n",
        "\n",
        "    def d(a, b):\n",
        "        return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
        "\n",
        "    def randomk():\n",
        "        def function_fix(a, b):\n",
        "          assert b >= a and a >= 0 and b >= 0 and a <= 1 and b <= 1\n",
        "          if self.function_fix_approx is None:\n",
        "            return b - a\n",
        "          return self.function_fix_approx[int(round(b * (len(self.function_fix_approx) - 1)))] - self.function_fix_approx[int(round(a * (len(self.function_fix_approx) - 1)))]\n",
        "      \n",
        "        K = 32\n",
        "        \n",
        "        x = np.arange(-y1, x1, (x1 + y1) / K)\n",
        "        y = [0] * len(x)\n",
        "        s = 0\n",
        "        \n",
        "        for i in range(1, len(x)):\n",
        "            l = x[i] - x[i - 1]\n",
        "            p = (x[i] + x[i - 1]) / 2\n",
        "            m1, m2 = cuts(p)\n",
        "            if len(m1) < 2 or len(m2) < 2:\n",
        "              y[i] = 0\n",
        "            else:\n",
        "              dx = x2 - x1\n",
        "              dm1x1 = x1 - max(m1[0][0], m1[1][0])\n",
        "              dm1x2 = x1 - min(m1[0][0], m1[1][0])\n",
        "              dm2x1 = min(m2[0][0], m2[1][0]) - x2\n",
        "              dm2x2 = max(m2[0][0], m2[1][0]) - x2\n",
        "              y[i] = function_fix(dx / (dx + dm1x2), dx / (dx + dm1x1)) * function_fix(dx / (dx + dm2x2), dx / (dx + dm2x1)) * l      \n",
        "            s += y[i]\n",
        "\n",
        "        r = random.uniform(0, s)\n",
        "\n",
        "        for i in range(1, len(x)):\n",
        "            if r - y[i] <= 0:\n",
        "                return random.uniform(x[i - 1], x[i])\n",
        "            r -= y[i]\n",
        "\n",
        "        return random.uniform(x[-2], x[-1])\n",
        "\n",
        "    def v(a, b):\n",
        "        return (b[0] - a[0], b[1] - a[1])\n",
        "\n",
        "    def m(a, b):\n",
        "        return (a[0] * b, a[1] * b)\n",
        "\n",
        "    def s(a, b):\n",
        "        return (b[0] + a[0], b[1] + a[1])\n",
        "      \n",
        "    def randomr(l, r):\n",
        "      assert l >= 0 and l <= 1 and r >= 0 and r <= 1 and l <= r\n",
        "      \n",
        "      if self.function_fix_approx is None:\n",
        "        return random.uniform(l, r)\n",
        "      \n",
        "      l = int(math.ceil(l * (len(self.function_fix_approx) - 1)))\n",
        "      r = int(math.floor(r * (len(self.function_fix_approx) - 1)))\n",
        "      \n",
        "      if l >= r:\n",
        "        return l\n",
        "      \n",
        "      x = random.uniform(self.function_fix_approx[l], self.function_fix_approx[r])\n",
        "      \n",
        "      i = int(round(x * (len(self.inverse_function_fix_approx) - 1)))\n",
        "      \n",
        "      return self.inverse_function_fix_approx[i]\n",
        "    \n",
        "    if x1 + y1 == 0:\n",
        "      return (None, None), (None, None)\n",
        "    \n",
        "    k = randomk()\n",
        "    m1, m2 = cuts(k)\n",
        "    \n",
        "    if len(m1) == 0 or len(m2) == 0:\n",
        "      return (None, None), (None, None)\n",
        "    \n",
        "    if m1[0][0] > m1[1][0]:\n",
        "      m1[0], m1[1] = m1[1], m1[0]\n",
        "    \n",
        "    if m2[0][0] > m2[1][0]:\n",
        "      m2[0], m2[1] = m2[1], m2[0]\n",
        "    \n",
        "    if len(m1) == 1:\n",
        "      v1 = (0, 0)\n",
        "    else:\n",
        "      v1 = v(m1[1], m1[0])\n",
        "    if len(m2) == 1:\n",
        "      v2 = (0, 0)\n",
        "    else:\n",
        "      v2 = v(m2[0], m2[1])\n",
        "\n",
        "    l1, l2 = d(m1[0], m1[1]), d(m2[0], m2[1])\n",
        "    \n",
        "    dx = x2 - x1\n",
        "    dm1x1 = x1 - max(m1[0][0], m1[1][0])\n",
        "    dm1x2 = x1 - min(m1[0][0], m1[1][0])\n",
        "    dm2x1 = min(m2[0][0], m2[1][0]) - x2\n",
        "    dm2x2 = max(m2[0][0], m2[1][0]) - x2\n",
        "    \n",
        "    if dm1x2 - dm1x1 == 0:\n",
        "      r1 = 0\n",
        "    else:\n",
        "      r1 = randomr(dx / (dx + dm1x2), dx / (dx + dm1x1))\n",
        "      r1 = dx * (1 - r1) / r1\n",
        "      r1 -= dm1x1\n",
        "      r1 /= dm1x2 - dm1x1\n",
        "      \n",
        "    if dm2x2 - dm2x1 == 0:\n",
        "      r2 = 0\n",
        "    else:\n",
        "      r2 = randomr(dx / (dx + dm2x2), dx / (dx + dm2x1))\n",
        "      r2 = dx * (1 - r2) / r2\n",
        "      r2 -= dm2x1\n",
        "      r2 /= dm2x2 - dm2x1\n",
        "\n",
        "    ans = (s(m1[1], m(v1, r1))), (s(m2[0], m(v2, r2)))\n",
        "    if ans[0][0] > ans[1][0]:\n",
        "        return (ans[1], ans[0])\n",
        "\n",
        "    return ans\n",
        "  \n",
        "  def __random_outside(self, W, H, x1, y1, x2, y2, min_size):\n",
        "    def random_quad_inside_rectangle(x1, y1, x2, y2):\n",
        "      maxd = min(x2 - x1, y2 - y1)\n",
        "      d = random.uniform(min_size, maxd)\n",
        "      shiftx = random.uniform(0, x2 - x1 - d)\n",
        "      shifty = random.uniform(0, y2 - y1 - d)\n",
        "\n",
        "      return (x1 + shiftx, y1 + shifty), (x1 + shiftx + d, y1 + shifty + d)\n",
        "\n",
        "    if min(H, x1) >= min_size:\n",
        "      Spl = H * x1\n",
        "    else:\n",
        "      Spl = 0\n",
        "    if min(H, W - x2) >= min_size:\n",
        "      Spr = H * (W - x2)\n",
        "    else:\n",
        "      Spr = 0\n",
        "    if min(W, H - y2) >= min_size:\n",
        "      Spu = W * (H - y2)\n",
        "    else:\n",
        "      Spu = 0\n",
        "    if min(W, y1) >= min_size:\n",
        "      Spd = W * y1\n",
        "    else:\n",
        "      Spd = 0\n",
        "    S = Spl + Spr + Spu + Spd\n",
        "\n",
        "    if S < 1e-9:\n",
        "      return (None, None), (None, None)\n",
        "\n",
        "    r = random.uniform(0, S)\n",
        "    if r <= Spl:\n",
        "      return random_quad_inside_rectangle(0, 0, x1, H)\n",
        "    elif r <= Spl + Spr:\n",
        "      return random_quad_inside_rectangle(x2, 0, W, H)\n",
        "    elif r <= Spl + Spr + Spu:\n",
        "      return random_quad_inside_rectangle(0, y2, W, H)\n",
        "    else:\n",
        "      return random_quad_inside_rectangle(0, 0, W, y1)\n",
        "  \n",
        "  @staticmethod\n",
        "  def __update_part(block_idx, part_size, config_data, parts_list):\n",
        "    j = block_idx * part_size\n",
        "    for i in range(part_size):\n",
        "      parts_list.push(np.asarray(Image.open(config_data[j][0]), dtype=np.uint8))\n",
        "      j += 1\n",
        "      if j == len(config_data):\n",
        "        j = 0\n",
        "  \n",
        "  def __parts_data_index(self, current_block, i):\n",
        "    j = current_block * self.part_size + i\n",
        "    if j >= len(self.config_data):\n",
        "      j-= len(self.config_data)\n",
        "    return j\n",
        "  \n",
        "  def __init__(self, config, images_prefix, image_size, batch_size, seed, parts_cnt, avg_bytes, grids, min_crop_size, attribute_mask, function_fix_approx=None, inverse_function_fix_approx=None, box_threshold=0.5, debug=False, min_face_size=2, nofaces_rate=0, nofaces_min_size=2, hs_range=15, g_prob=0.5, g_max=0.6, flip_prob=0.5, noise_level=0.05, noise_prob=0.5, noise_channel_prob=0.5, contrast_norm_min=0.75, contrast_norm_max=1.5, boxes_only = False, size_index=None):\n",
        "    assert parts_cnt > 1\n",
        "    \n",
        "    self.config_data = []\n",
        "    \n",
        "    max_boxes = 0\n",
        "    cf = open(config, \"r\")\n",
        "    while True:\n",
        "      take_image = True\n",
        "      image = cf.readline()[:-1]\n",
        "      if len(image) <= 1:\n",
        "        break\n",
        "      config_item = [images_prefix + \"/\" + image, [], \"\"]\n",
        "      n = int(cf.readline())\n",
        "      for i in range(n):\n",
        "        x1, y1, w, h, blur, expression, illumination, invalid, occlusion, pose = list(map(int, cf.readline().split()))\n",
        "        if x1 >= 0 and y1 >= 0 and w >= 2 and h >= 2:\n",
        "          config_item[1].append((x1, y1, w, h, not(attribute_mask(blur, expression, illumination, invalid, occlusion, pose))))\n",
        "        else:\n",
        "          take_image = False\n",
        "      if len(config_item[1]) > 0 and take_image:\n",
        "        max_boxes = max(max_boxes, len(config_item[1]))\n",
        "        config_item[2] = image\n",
        "        self.config_data.append(config_item)\n",
        "    cf.close()\n",
        "    \n",
        "    self.debug = debug\n",
        "    \n",
        "    if self.debug:\n",
        "      print(\"DEBUG: metadata loaded, %d images total, %d max boxes\" % (len(self.config_data), max_boxes))\n",
        "    \n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(self.config_data)\n",
        "    self.min_face_size = min_face_size\n",
        "    self.boxes_only = boxes_only\n",
        "    self.nofaces_rate = nofaces_rate\n",
        "    self.nofaces_min_size = nofaces_min_size\n",
        "    self.conflicts = 0\n",
        "    self.grids = grids\n",
        "    self.function_fix_approx = function_fix_approx\n",
        "    self.inverse_function_fix_approx = inverse_function_fix_approx\n",
        "    self.skipped = 0\n",
        "    self.image_size = image_size\n",
        "    self.box_threshold = box_threshold\n",
        "    self.i = 0\n",
        "    self.batch_size = batch_size\n",
        "    self.part_size = len(self.config_data) // parts_cnt\n",
        "    self.parts_cnt = parts_cnt\n",
        "    if not(self.boxes_only):\n",
        "      self.parts = [SharedImageArray(avg_bytes * self.part_size, self.part_size), SharedImageArray(avg_bytes * self.part_size, self.part_size)]\n",
        "    self.hs_range = hs_range\n",
        "    self.g_prob = g_prob\n",
        "    self.g_max = g_max\n",
        "    self.flip_prob = flip_prob\n",
        "    self.noise_level = noise_level\n",
        "    self.noise_prob = noise_prob\n",
        "    self.noise_channel_prob = noise_channel_prob\n",
        "    self.contrast_norm_min = contrast_norm_min\n",
        "    self.contrast_norm_max = contrast_norm_max\n",
        "    self.min_crop_size = min_crop_size\n",
        "    if size_index is None:\n",
        "      self.size_index = None\n",
        "    else:\n",
        "      self.size_index = dict()\n",
        "      sif = open(size_index, \"r\")\n",
        "      for line in sif.readlines():\n",
        "        fname, w, h = line[:-1].split()\n",
        "        w = int(w)\n",
        "        h = int(h)\n",
        "        self.size_index[fname] = (w, h)\n",
        "    \n",
        "    if self.debug:\n",
        "      print(\"DEBUG: loading initial data\")\n",
        "    if not(self.boxes_only):\n",
        "      self.__update_part(0, self.part_size, self.config_data, self.parts[0])\n",
        "    if self.debug:\n",
        "      print(\"DEBUG: initial data loaded\")\n",
        "    \n",
        "    self.current_part = 0\n",
        "    self.current_block = 0\n",
        "    self.block_idx = 1\n",
        "    self.part_status = [1, 0]\n",
        "    self.color_augmentations = ia.Sequential([\n",
        "      ia.AddToHueAndSaturation((-self.hs_range, self.hs_range)),\n",
        "      ia.Sometimes(self.g_prob, ia.Grayscale((0, self.g_max))),\n",
        "      ia.ContrastNormalization((self.contrast_norm_min, self.contrast_norm_max)),\n",
        "      ia.Sometimes(self.noise_prob, ia.AdditiveGaussianNoise(loc=0, scale=(0.0, self.noise_level * 255), per_channel=self.noise_channel_prob))\n",
        "    ])\n",
        "   \n",
        "  def __intersect_sections(self, ax1, ax2, bx1, bx2):\n",
        "    if ax1 > bx1:\n",
        "      ax1, bx1 = bx1, ax1\n",
        "      ax2, bx2 = bx2, ax2\n",
        "    \n",
        "    if ax2 <= bx1:\n",
        "      return None, None\n",
        "    \n",
        "    return bx1, min(ax2, bx2)\n",
        "  \n",
        "  def __intersect_boxes(self, ax1, ay1, ax2, ay2, bx1, by1, bx2, by2):\n",
        "    assert ax2 >= ax1 and ay2 >= ay1 and bx2 >= bx1 and by2 >= by1\n",
        "    \n",
        "    sa = (ax2 - ax1) * (ay2 - ay1)\n",
        "    sb = (bx2 - bx1) * (by2 - by1)\n",
        "    \n",
        "    if sa == 0 or sb == 0:\n",
        "      return None, None, None, None, None\n",
        "    \n",
        "    ix1, ix2 = self.__intersect_sections(ax1, ax2, bx1, bx2)\n",
        "    iy1, iy2 = self.__intersect_sections(ay1, ay2, by1, by2)\n",
        "    \n",
        "    if ix1 is None or iy1 is None:\n",
        "      return None, None, None, None, None\n",
        "    \n",
        "    si = (ix2 - ix1) * (iy2 - iy1)\n",
        "    \n",
        "    if si == 0:\n",
        "      return None, None, None, None, None\n",
        "    \n",
        "    relsize = si / min(sa, sb)\n",
        "    \n",
        "    return ix1, iy1, ix2, iy2, relsize\n",
        "  \n",
        "  def color_augmentations(self, image_batch):\n",
        "    return self.color_augmentations.augment_images(image_batch)\n",
        "  \n",
        "  def flow(self):\n",
        "    while True:\n",
        "      if self.part_status[1 - self.current_part] == 0 and not(self.boxes_only):\n",
        "        if self.debug:\n",
        "          print(\"DEBUG: loading additional data\")\n",
        "        self.parts[1 - self.current_part].clear()\n",
        "        self.part_loader = Process(target=self.__update_part, args=(self.block_idx, self.part_size, self.config_data, self.parts[1 - self.current_part]))\n",
        "        self.part_loader.start()\n",
        "        self.part_status[1 - self.current_part] = -1\n",
        "        \n",
        "      if not(self.boxes_only) and not(self.part_loader.is_alive()) and self.part_status[1 - self.current_part] == -1:\n",
        "        if self.debug:\n",
        "          print(\"DEBUG: additional data loaded\")\n",
        "        self.part_status[1 - self.current_part] = 1\n",
        "      \n",
        "      if self.boxes_only:\n",
        "        self.part_status[1 - self.current_part] = 1\n",
        "      \n",
        "      if self.part_status[self.current_part] == 2 and self.part_status[1 - self.current_part] == 1:\n",
        "        if self.debug:\n",
        "          print(\"DEBUG: parts flip flop\")\n",
        "        self.current_part = 1 - self.current_part\n",
        "        self.part_status[1 - self.current_part] = 0\n",
        "        \n",
        "        self.i = 0\n",
        "        self.current_block = self.block_idx\n",
        "        self.block_idx += 1\n",
        "        if self.block_idx == self.parts_cnt:\n",
        "          self.block_idx = 0\n",
        "        continue\n",
        "      \n",
        "      if not(self.boxes_only):\n",
        "        x_yield = np.zeros((self.batch_size, self.image_size, self.image_size, 3), dtype=np.uint8)\n",
        "      y_yield = []\n",
        "      if not(self.boxes_only):\n",
        "        for i in range(len(self.grids)):\n",
        "          y_yield.append(np.zeros((self.batch_size, self.grids[i], self.grids[i], 6), dtype=np.float))\n",
        "      \n",
        "      for k in range(self.batch_size):\n",
        "        while True:\n",
        "          if not(self.boxes_only):\n",
        "            image = self.parts[self.current_part].get(self.i)\n",
        "            H = image.shape[0]\n",
        "            W = image.shape[1]\n",
        "          else:\n",
        "            image_name = self.config_data[self.__parts_data_index(self.current_block, self.i)][2]\n",
        "            W, H = self.size_index[image_name]\n",
        "          boxes = self.config_data[self.__parts_data_index(self.current_block, self.i)][1]\n",
        "          if random.uniform(0, 1) < self.nofaces_rate:\n",
        "            x1, y1, w, h, hard = boxes[0]\n",
        "            y1 = (H - 1) - y1 - h\n",
        "            x2 = x1 + w\n",
        "            y2 = y1 + h\n",
        "            for i in range(1, len(boxes)):\n",
        "              cx1, cy1, cw, ch, hard = boxes[i]\n",
        "              cy1 = (H - 1) - cy1 - ch\n",
        "              cx2 = cx1 + cw\n",
        "              cy2 = cy1 + ch\n",
        "              \n",
        "              y1 = min(y1, cy1)\n",
        "              y2 = max(y2, cy2)\n",
        "              x1 = min(x1, cx1)\n",
        "              x2 = max(x2, cx2)\n",
        "              \n",
        "            (qx1, qy1), (qx2, qy2) = self.__random_outside(W - 1, H - 1, x1, y1, x2, y2, self.nofaces_min_size)\n",
        "            if qx1 is None:\n",
        "              self.skipped += 1\n",
        "              self.i += 1\n",
        "              if self.i == self.part_size:\n",
        "                self.i = 0\n",
        "                self.part_status[self.current_part] = 2\n",
        "            else:\n",
        "              break\n",
        "              \n",
        "          else:\n",
        "            not_hard_indexes = []\n",
        "            for i in range(len(boxes)):\n",
        "              if not(boxes[i][4]):\n",
        "                not_hard_indexes.append(i)\n",
        "            if len(not_hard_indexes) == 0:\n",
        "              self.skipped += 1\n",
        "              self.i += 1\n",
        "              if self.i == self.part_size:\n",
        "                self.i = 0\n",
        "                self.part_status[self.current_part] = 2\n",
        "              continue\n",
        "            \n",
        "            keep_face = random.randint(0, len(not_hard_indexes) - 1)\n",
        "            x1, y1, w, h, hard = boxes[not_hard_indexes[keep_face]]\n",
        "            y1 = (H - 1) - y1 - h\n",
        "            x2 = x1 + w\n",
        "            y2 = y1 + h\n",
        "            (qx1, qy1), (qx2, qy2) = self.__random_quad(x1, y1, x2, y2, W - 1, H - 1)\n",
        "            if qx1 is None or qx1 < 0 or qx2 < 0 or qy1 < 0 or qy2 < 0 or qx1 > W - 1 or qx2 > W - 1 or qy1 > H - 1 or qy2 > H - 1 or qx2 - qx1 < self.min_crop_size or qy2 - qy1 < self.min_crop_size:\n",
        "              self.skipped += 1\n",
        "              self.i += 1\n",
        "              if self.i == self.part_size:\n",
        "                self.i = 0\n",
        "                self.part_status[self.current_part] = 2\n",
        "            else:\n",
        "              break\n",
        "            \n",
        "        qy1 = (H - 1) - int(qy1)\n",
        "        qx1 = int(qx1)\n",
        "        qy2 = (H - 1) - int(qy2)\n",
        "        qx2 = int(qx2)\n",
        "        qy1, qy2 = qy2, qy1\n",
        "        \n",
        "        if qx2 - qx1 == qy2 - qy1 + 1:\n",
        "          qx1 += 1\n",
        "        elif qy2 - qy1 == qx2 - qx1 + 1:\n",
        "          qy1 += 1\n",
        "        \n",
        "        if not(self.boxes_only):\n",
        "          x_yield[k] = cv2.resize(image[qy1:(qy2 + 1), qx1:(qx2 + 1)], (self.image_size, self.image_size))\n",
        "        \n",
        "        if random.uniform(0, 1) <= self.flip_prob:\n",
        "          fliplr = True\n",
        "          if not(self.boxes_only):\n",
        "            x_yield[k] = np.fliplr(x_yield[k])\n",
        "        else:\n",
        "          fliplr = False\n",
        "        \n",
        "        downsample = 1 / (qy2 - qy1 + 1)\n",
        "        \n",
        "        if not(self.boxes_only):\n",
        "          for box_x1, box_y1, box_w, box_h, hard in boxes:\n",
        "            ibox_x1, ibox_y1, ibox_x2, ibox_y2, relsize = self.__intersect_boxes(box_x1, box_y1, box_x1 + box_w, box_y1 + box_h, qx1, qy1, qx2, qy2)\n",
        "            if not(ibox_x1 is None):\n",
        "              if relsize < self.box_threshold:\n",
        "                hard = True\n",
        "              ibox = [(ibox_x1 - qx1) * downsample, (ibox_y1 - qy1) * downsample, (ibox_x2 - qx1) * downsample, (ibox_y2 - qy1) * downsample]\n",
        "              if fliplr:\n",
        "                ibox[0] = 1 - ibox[0]\n",
        "                ibox[2] = 1 - ibox[2]\n",
        "                ibox[0], ibox[2] = ibox[2], ibox[0]\n",
        "              wx = ibox[2] - ibox[0]\n",
        "              wy = ibox[3] - ibox[1]\n",
        "              cx = ibox[0] + wx / 2\n",
        "              cy = ibox[1] + wy / 2\n",
        "              \n",
        "              if wx < self.min_face_size or wy < self.min_face_size:\n",
        "                hard = True\n",
        "\n",
        "              for grid in range(len(self.grids)):\n",
        "                grid_i = min(int(cx * self.grids[grid]), self.grids[grid] - 1)\n",
        "                grid_j = min(int(cy * self.grids[grid]), self.grids[grid] - 1)\n",
        "                sx = (cx - grid_i / self.grids[grid]) * self.grids[grid]\n",
        "                sy = (cy - grid_j / self.grids[grid]) * self.grids[grid]\n",
        "\n",
        "                if y_yield[grid][k][grid_i][grid_j][4] == 1:\n",
        "                    self.conflicts += 1\n",
        "\n",
        "                if not(hard) and (y_yield[grid][k][grid_i][grid_j][4] == 0 or y_yield[grid][k][grid_i][grid_j][2] * y_yield[grid][k][grid_i][grid_j][3] < wx * self.grids[grid] * wy * self.grids[grid]):\n",
        "                  y_yield[grid][k][grid_i][grid_j] = (sx,  sy,  wx * self.grids[grid],  wy * self.grids[grid], 1, 0)\n",
        "                  \n",
        "                if hard and y_yield[grid][k][grid_i][grid_j][4] == 0 and (y_yield[grid][k][grid_i][grid_j][5] == 0 or y_yield[grid][k][grid_i][grid_j][2] * y_yield[grid][k][grid_i][grid_j][3] < wx * self.grids[grid] * wy * self.grids[grid]):\n",
        "                  y_yield[grid][k][grid_i][grid_j] = (sx,  sy,  wx * self.grids[grid],  wy * self.grids[grid], 0, 1)\n",
        "        else:\n",
        "          c_yield = []\n",
        "          for box_x1, box_y1, box_w, box_h, hard in boxes:\n",
        "            ibox_x1, ibox_y1, ibox_x2, ibox_y2, relsize = self.__intersect_boxes(box_x1, box_y1, box_x1 + box_w, box_y1 + box_h, qx1, qy1, qx2, qy2)\n",
        "            if not(ibox_x1 is None):\n",
        "              if relsize < self.box_threshold:\n",
        "                hard = True\n",
        "              ibox = [(ibox_x1 - qx1) * downsample, (ibox_y1 - qy1) * downsample, (ibox_x2 - qx1) * downsample, (ibox_y2 - qy1) * downsample]\n",
        "              if fliplr:\n",
        "                ibox[0] = 1 - ibox[0]\n",
        "                ibox[2] = 1 - ibox[2]\n",
        "                ibox[0], ibox[2] = ibox[2], ibox[0]\n",
        "              wx = ibox[2] - ibox[0]\n",
        "              wy = ibox[3] - ibox[1]\n",
        "              \n",
        "              if wx < self.min_face_size or wy < self.min_face_size:\n",
        "                  hard = True\n",
        "                  \n",
        "              if not(hard):\n",
        "                c_yield.append(ibox)\n",
        "          y_yield.append(c_yield)\n",
        "        \n",
        "        \n",
        "        self.i += 1\n",
        "        if self.i == self.part_size:\n",
        "          self.i = 0\n",
        "          self.part_status[self.current_part] = 2\n",
        "          \n",
        "      if self.debug:\n",
        "        print(\"DEBUG: %d images skipped, %d conflicts\" % (self.skipped, self.conflicts))\n",
        "      self.skipped = 0\n",
        "      self.conflicts = 0\n",
        "      if self.boxes_only:\n",
        "        yield(y_yield)\n",
        "      else:\n",
        "        yield((self.color_augmentations.augment_images(x_yield), y_yield))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9bkfUmxKGI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def distribution_histogram(function_fix, inverse_functiom_fix, num_batches, num_bins=20):\n",
        "  boxes = []\n",
        "  generator = DataPipeline(TRAIN_BBX_PATH, TRAIN_IMAGES_PREFIX, IMAGE_SIZE, BATCH_SIZE, SEED, TRAIN_NUM_PARTS, AVG_BYTES, GRIDS, MIN_CROP_SIZE, ATTRIBUTE_MASK, function_fix, inverse_functiom_fix, BOX_THRESHOLD, DEBUG, MIN_FACE_SIZE, NOFACES_RATE, NOFACES_MIN_SIZE, HS_RANGE, G_PROB, G_MAX, FLIP_PROB, NOISE_LEVEL, NOISE_PROB, NOISE_CHANNEL_PROB, CONTRAST_NORM_MIN, CONTRAST_NORM_MAX, True, SIZE_INDEX)\n",
        "  flow = generator.flow()\n",
        "  for i in range(num_batches):\n",
        "    batch = next(flow)\n",
        "    for image in batch:\n",
        "      for box in image:\n",
        "        boxes.append((box[2] - box[0], box[3] - box[1]))\n",
        "  boxes = np.array(boxes)\n",
        "  histogram = np.array(np.histogram(np.array(boxes[:, 1], dtype=np.float32), bins=num_bins, range=(0, 1))[0], dtype=np.float32)\n",
        "  histogram /= np.mean(histogram)\n",
        "  \n",
        "  return histogram\n",
        "\n",
        "def distribution_loss(function_fix, inverse_functiom_fix, num_batches, num_bins=20):\n",
        "  return np.std(distribution_histogram(function_fix, inverse_functiom_fix, num_batches, num_bins))\n",
        "\n",
        "def inverse_distribution_function(f, k):\n",
        "  inv = np.zeros((k,))\n",
        "  for i in range(len(f)):\n",
        "    inv[int(math.ceil(f[i] * (k - 1)))] = i / (len(f) - 1)\n",
        "    inv[int(math.floor(f[i] * (k - 1)))] = i / (len(f) - 1)\n",
        "  inv[0] = 0\n",
        "  inv[k - 1] = 1\n",
        "  for i in range(k):\n",
        "    if i != 0 and i != k - 1 and inv[i] == 0:\n",
        "      if inv[i - 1] != 0 and inv[i + 1] != 0:\n",
        "        inv[i] = inv[i - 1] / 2 + inv[i + 1] / 2\n",
        "      else:\n",
        "        inv[i] = inv[i - 1] + inv[i + 1]\n",
        "    \n",
        "  return inv\n",
        "\n",
        "def density_to_function(d):\n",
        "  f = np.zeros((len(d) + 1,))\n",
        "  f[0] = 0\n",
        "  f[1] = d[0] / len(d)\n",
        "  for i in range(1, len(d)):\n",
        "    f[i + 1] = f[i] + d[i] / len(d)\n",
        "  f[len(d)] = 1\n",
        "  return f\n",
        "\n",
        "def function_space(p, k=100000):\n",
        "  f = np.linspace(0, 1, k) ** p[0] + p[1]\n",
        "  f /= np.mean(f)\n",
        "  return f\n",
        "\n",
        "def f(p, num_batches=300, num_bins=20):\n",
        "  d = function_space(p)\n",
        "  f = density_to_function(d)\n",
        "  invf = inverse_distribution_function(f, len(f))\n",
        "  return distribution_loss(f, invf, num_batches, num_bins)\n",
        "\n",
        "def f_hist(p, num_batches=300, num_bins=20):\n",
        "  d = function_space(p)\n",
        "  f = density_to_function(d)\n",
        "  invf = inverse_distribution_function(f, len(f))\n",
        "  return distribution_histogram(f, invf, num_batches, num_bins)\n",
        "\n",
        "def gridsearch(pspace, cspace, num_batches=1000):\n",
        "  best_val = 1e9\n",
        "  best_p = -1\n",
        "  best_c = -1\n",
        "  heatmap = np.zeros((len(pspace), len(cspace),), dtype=np.float32)\n",
        "  for i in range(len(pspace)):\n",
        "    for j in range(len(cspace)):\n",
        "      p = pspace[i]\n",
        "      c = cspace[j]\n",
        "      val = f([p, c], num_batches)\n",
        "      if val < best_val:\n",
        "        best_val = val\n",
        "        best_p = p\n",
        "        best_c = c\n",
        "      print(p, c, val)\n",
        "      heatmap[i][j] = val\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.contourf(pspace, cspace, heatmap, cmap='jet')\n",
        "  plt.show()\n",
        "  \n",
        "  return (best_p, best_c, best_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9ntdfLL0cF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#gridsearch(np.linspace(0, 3, 10), np.linspace(0, 1, 10), 64000 // BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vn1dibxskFIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "P = 0\n",
        "C = 1\n",
        "\n",
        "plt.plot(f_hist([P, C], 64000 // BATCH_SIZE, 100))\n",
        "DENSITY_FIX_APPROX = function_space([P, C])\n",
        "FUNCTION_FIX_APPROX = density_to_function(DENSITY_FIX_APPROX)\n",
        "INVERSE_FUNCTION_FIX_APPROX = inverse_distribution_function(FUNCTION_FIX_APPROX, len(FUNCTION_FIX_APPROX))\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(FUNCTION_FIX_APPROX)\n",
        "plt.plot(INVERSE_FUNCTION_FIX_APPROX)\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(DENSITY_FIX_APPROX)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bVgh1QHRFQBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_generator = DataPipeline(TRAIN_BBX_PATH, TRAIN_IMAGES_PREFIX, IMAGE_SIZE, BATCH_SIZE, SEED, TRAIN_NUM_PARTS, AVG_BYTES, GRIDS, MIN_CROP_SIZE, ATTRIBUTE_MASK, FUNCTION_FIX_APPROX, INVERSE_FUNCTION_FIX_APPROX, BOX_THRESHOLD, DEBUG, MIN_FACE_SIZE, NOFACES_RATE, NOFACES_MIN_SIZE, HS_RANGE, G_PROB, G_MAX, FLIP_PROB, NOISE_LEVEL, NOISE_PROB, NOISE_CHANNEL_PROB, CONTRAST_NORM_MIN, CONTRAST_NORM_MAX, False, None)\n",
        "train_flow = train_generator.flow()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ZLF3ZJOM6ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_generator = DataPipeline(VAL_BBX_PATH, VAL_IMAGES_PREFIX, IMAGE_SIZE, BATCH_SIZE, SEED, VAL_NUM_PARTS, AVG_BYTES, GRIDS, MIN_CROP_SIZE, ATTRIBUTE_MASK, FUNCTION_FIX_APPROX, INVERSE_FUNCTION_FIX_APPROX, BOX_THRESHOLD, DEBUG, MIN_FACE_SIZE, NOFACES_RATE, NOFACES_MIN_SIZE, HS_RANGE, G_PROB, G_MAX, FLIP_PROB, NOISE_LEVEL, NOISE_PROB, NOISE_CHANNEL_PROB, CONTRAST_NORM_MIN, CONTRAST_NORM_MAX, False, None)\n",
        "val_flow = val_generator.flow()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5OG_-hLih6U1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualise_batch_with_boxes(batch):\n",
        "  for i in range(BATCH_SIZE):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(batch[0][i])\n",
        "    for g in range(len(GRIDS)):\n",
        "      for x in range(GRIDS[g]):\n",
        "        for y in range(GRIDS[g]):\n",
        "          p = batch[1][g][i][x][y][4]\n",
        "          hard = batch[1][g][i][x][y][5]\n",
        "          if p == 1 or hard == 1:\n",
        "            cx = x + batch[1][g][i][x][y][0]\n",
        "            cy = y + batch[1][g][i][x][y][1]\n",
        "            wx = batch[1][g][i][x][y][2]\n",
        "            wy = batch[1][g][i][x][y][3]\n",
        "            lx = cx - wx / 2\n",
        "            ly = cy - wy / 2\n",
        "            rx = cx + wx / 2\n",
        "            ry = cy + wy / 2\n",
        "            lx = int(round(lx * IMAGE_SIZE / GRIDS[g]))\n",
        "            rx = int(round(rx * IMAGE_SIZE / GRIDS[g]))\n",
        "            ly = int(round(ly * IMAGE_SIZE / GRIDS[g]))\n",
        "            ry = int(round(ry * IMAGE_SIZE / GRIDS[g]))\n",
        "            if hard == 0:\n",
        "              plt.gca().add_patch(Rectangle((lx,ly),rx - lx,ry - ly,linewidth=2,edgecolor='g',facecolor='none'))\n",
        "            else:\n",
        "              plt.gca().add_patch(Rectangle((lx,ly),rx - lx,ry - ly,linewidth=2,edgecolor='r',facecolor='none'))\n",
        "    plt.show()\n",
        "\n",
        "def measure_batch_time(flow):\n",
        "  start = time.time()\n",
        "  batch = next(flow)\n",
        "  print(\"Batch time: \" + str(time.time() - start))\n",
        "  return batch\n",
        "\n",
        "#visualise_batch_with_boxes(measure_batch_time(train_flow))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NxrfyDCqSDy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LAMBDA_BOXES = 1\n",
        "LAMBDA_CONFIDENCE = 3/4\n",
        "LAMBDA_FP = 1/4\n",
        "EPS = 1e-9\n",
        "ALPHA = 0.1\n",
        "IOU_THRESHOLD = 0.8\n",
        "\n",
        "def yolo_like_loss_exp(y_true, y_pred):\n",
        "  grid_size = int(y_pred.shape.as_list()[1])\n",
        "  \n",
        "  tcx     = tf.reshape(y_true[..., 0], (-1, grid_size ** 2))\n",
        "  tcy     = tf.reshape(y_true[..., 1], (-1, grid_size ** 2))\n",
        "  twx     = tf.reshape(y_true[..., 2], (-1, grid_size ** 2))\n",
        "  twy     = tf.reshape(y_true[..., 3], (-1, grid_size ** 2))\n",
        "  exists  = tf.reshape(y_true[..., 4], (-1, grid_size ** 2))\n",
        "  #hard  = tf.reshape(y_true[..., 5], (-1, grid_size ** 2))\n",
        "  \n",
        "  pcx = tf.sigmoid(tf.reshape(y_pred[..., 0], (-1, grid_size ** 2)))\n",
        "  pcy = tf.sigmoid(tf.reshape(y_pred[..., 1], (-1, grid_size ** 2)))\n",
        "  y_pred_2 = tf.reshape(y_pred[..., 2], (-1, grid_size ** 2))\n",
        "  pwx = tf.minimum(tf.exp(y_pred_2 / grid_size), grid_size) + tf.maximum(ALPHA * (y_pred_2 - grid_size * math.log(grid_size)), 0)\n",
        "  y_pred_3 = tf.reshape(y_pred[..., 3], (-1, grid_size ** 2))\n",
        "  pwy = tf.minimum(tf.exp(y_pred_3 / grid_size), grid_size) + tf.maximum(ALPHA * (y_pred_3 - grid_size * math.log(grid_size)), 0)\n",
        "  p   = tf.sigmoid(tf.reshape(y_pred[..., 4], (-1, grid_size ** 2)))\n",
        "  \n",
        "  loss_boxes = tf.reduce_sum(exists * ((tcx - pcx) ** 2 + (tcy - pcy) ** 2 + (tf.sqrt(twx) - tf.sqrt(pwx)) ** 2 + (tf.sqrt(twy) - tf.sqrt(pwy)) ** 2)) / (tf.reduce_sum(exists) + EPS)\n",
        "  \n",
        "  tx1 = tcx - twx / 2\n",
        "  tx2 = tcx + twx / 2\n",
        "  ty1 = tcy - twy / 2\n",
        "  ty2 = tcy + twy / 2\n",
        "  \n",
        "  px1 = pcx - pwx / 2\n",
        "  px2 = pcx + pwx / 2\n",
        "  py1 = pcy - pwy / 2\n",
        "  py2 = pcy + pwy / 2\n",
        "  \n",
        "  tx1p = tf.reshape(tf.tile(tx1, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2))\n",
        "  tx2p = tf.reshape(tf.tile(tx2, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2))\n",
        "  ty1p = tf.reshape(tf.tile(ty1, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2))\n",
        "  ty2p = tf.reshape(tf.tile(ty2, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2))\n",
        "  \n",
        "  px1p = tf.transpose(tf.reshape(tf.tile(px1, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2)), (0, 2, 1))\n",
        "  px2p = tf.transpose(tf.reshape(tf.tile(px2, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2)), (0, 2, 1))\n",
        "  py1p = tf.transpose(tf.reshape(tf.tile(py1, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2)), (0, 2, 1))\n",
        "  py2p = tf.transpose(tf.reshape(tf.tile(py2, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2)), (0, 2, 1))\n",
        "  \n",
        "  twxp = tf.reshape(tf.tile(twx, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2))\n",
        "  twyp = tf.reshape(tf.tile(twy, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2))\n",
        "  \n",
        "  pwxp = tf.transpose(tf.reshape(tf.tile(pwx, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2)), (0, 2, 1))\n",
        "  pwyp = tf.transpose(tf.reshape(tf.tile(pwy, (1, grid_size ** 2)), (-1, grid_size ** 2, grid_size ** 2)), (0, 2, 1))\n",
        "  \n",
        "  intersectionp = tf.maximum(tf.minimum(tx2p, px2p) - tf.maximum(tx1p, px1p), 0) * tf.maximum(tf.minimum(ty2p, py2p) - tf.maximum(ty1p, py1p), 0)\n",
        "  ioup = intersectionp / (twxp * twyp + pwxp * pwyp - intersectionp + EPS)\n",
        "  \n",
        "  fp_mask = tf.cast(tf.reduce_max(ioup, axis=2) < IOU_THRESHOLD, tf.float32)\n",
        "  \n",
        "  intersection = tf.maximum(tf.minimum(tx2, px2) - tf.maximum(tx1, px1), 0) * tf.maximum(tf.minimum(ty2, py2) - tf.maximum(ty1, py1), 0)\n",
        "  iou = intersection / (twx * twy + pwx * pwy - intersection + EPS)\n",
        "  \n",
        "  loss_confidence = tf.reduce_sum(exists * (iou - p) ** 2) / (tf.reduce_sum((1 - exists) * fp_mask) + tf.reduce_sum(exists) + EPS)\n",
        "  \n",
        "  loss_fp = tf.reduce_sum((1 - exists) * fp_mask * p ** 2) / (tf.reduce_sum((1 - exists) * fp_mask) + tf.reduce_sum(exists) + EPS)\n",
        "  \n",
        "  return LAMBDA_BOXES * loss_boxes + LAMBDA_CONFIDENCE * loss_confidence + LAMBDA_FP * loss_fp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qj4dCmWz94so",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_SgS9XqHaMRj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "output_tensor = MobileNetV2(input_tensor=input_tensor, alpha=0.75, weights=None, include_top=False).output\n",
        "output_tensor = ZeroPadding2D()(output_tensor)\n",
        "output_tensor = Conv2D(kernel_size=(3, 3), filters=5)(output_tensor)\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLrzvhNiwiPe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DfT9ioOF5w_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.load_weights(\"1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nx6ncwTlMfdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "STEPS = 1024\n",
        "EPOCHS = 30\n",
        "VAL_STEPS = STEPS // 4\n",
        "INITIAL_EPOCH = 0\n",
        "\n",
        "model.compile(optimizer=Adam(lr=1e-3), loss=yolo_like_loss_exp)\n",
        "\n",
        "checkpointer = ModelCheckpoint(\"tmp19.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "lr_scheldure = LearningRateScheduler(lambda epoch, lr: 0.9 ** epoch * 1e-3, verbose=1)\n",
        "\n",
        "model.fit_generator(\n",
        "                    train_flow,\n",
        "                    steps_per_epoch=STEPS,\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,\n",
        "                    use_multiprocessing=False,\n",
        "                    workers=1,\n",
        "                    validation_data=val_flow,\n",
        "                    validation_steps=VAL_STEPS,\n",
        "                    initial_epoch=INITIAL_EPOCH,\n",
        "                    callbacks=[checkpointer, lr_scheldure]\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dfiK4uCUuWIj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(\"new5.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5IMuDiA7LDVt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Init_PyDrive()\n",
        "Upload_File(\"tmp19.h5\", \"tmp19.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JeUL2jQk-nJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Init_PyDrive()\n",
        "Download_File(\"tmp18.h5\", \"1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inX3POxv0n76",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}